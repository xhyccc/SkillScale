# SkillScale — Docker Compose for Local Development
#
# Topology:
#   agent ──PUB──▶ proxy (XSUB:5444) ──▶ proxy (XPUB:5555) ──SUB──▶ skill-server-*
#   agent ◀──SUB── proxy (XPUB:5555) ◀──PUB── skill-server-*
#

services:
  # ── Central XPUB/XSUB Proxy ──
  proxy:
    build:
      context: .
      dockerfile: docker/Dockerfile.proxy
    ports:
      - "5444:5444"   # XSUB — publishers connect here
      - "5555:5555"   # XPUB — subscribers connect here
      - "9100:9100"   # Prometheus metrics
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "echo | nc -z localhost 5444"]
      interval: 5s
      timeout: 3s
      retries: 5

  # ── Skill Server: data-processing topic (C++ + npm OpenSkills CLI) ──
  skill-server-data:
    build:
      context: .
      dockerfile: docker/Dockerfile.skill-server
    environment:
      SKILLSCALE_TOPIC: TOPIC_DATA_PROCESSING
      SKILLSCALE_DESCRIPTION: "Data processing server — text summarization, CSV analysis, and general data transformation"
      SKILLSCALE_SKILLS_DIR: /skills
      SKILLSCALE_PROXY_XPUB: tcp://proxy:5555
      SKILLSCALE_PROXY_XSUB: tcp://proxy:5444
      SKILLSCALE_WORKERS: "2"
      SKILLSCALE_TIMEOUT: "120"
      LLM_PROVIDER: "${LLM_PROVIDER:-azure}"
      AZURE_API_KEY: "${AZURE_API_KEY}"
      AZURE_API_BASE: "${AZURE_API_BASE}"
      AZURE_MODEL: "${AZURE_MODEL:-gpt-4o}"
      AZURE_API_VERSION: "${AZURE_API_VERSION:-2024-12-01-preview}"
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      OPENAI_API_BASE: "${OPENAI_API_BASE}"
      OPENAI_MODEL: "${OPENAI_MODEL}"
      ZHIPU_API_KEY: "${ZHIPU_API_KEY}"
      ZHIPU_MODEL: "${ZHIPU_MODEL}"
    volumes:
      - ./skills/data-processing:/skills:ro
      - ./skills/llm_utils.py:/app/skills/llm_utils.py:ro
      - ./.claude/skills:/app/.claude/skills:ro
      - ./.env:/app/.env:ro
    depends_on:
      proxy:
        condition: service_healthy
    restart: unless-stopped

  # ── Skill Server: code-analysis topic (C++ + npm OpenSkills CLI) ──
  skill-server-code:
    build:
      context: .
      dockerfile: docker/Dockerfile.skill-server
    environment:
      SKILLSCALE_TOPIC: TOPIC_CODE_ANALYSIS
      SKILLSCALE_DESCRIPTION: "Code analysis server — cyclomatic complexity, static analysis, and code metrics"
      SKILLSCALE_SKILLS_DIR: /skills
      SKILLSCALE_PROXY_XPUB: tcp://proxy:5555
      SKILLSCALE_PROXY_XSUB: tcp://proxy:5444
      SKILLSCALE_WORKERS: "2"
      SKILLSCALE_TIMEOUT: "120"
      LLM_PROVIDER: "${LLM_PROVIDER:-azure}"
      AZURE_API_KEY: "${AZURE_API_KEY}"
      AZURE_API_BASE: "${AZURE_API_BASE}"
      AZURE_MODEL: "${AZURE_MODEL:-gpt-4o}"
      AZURE_API_VERSION: "${AZURE_API_VERSION:-2024-12-01-preview}"
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      OPENAI_API_BASE: "${OPENAI_API_BASE}"
      OPENAI_MODEL: "${OPENAI_MODEL}"
      ZHIPU_API_KEY: "${ZHIPU_API_KEY}"
      ZHIPU_MODEL: "${ZHIPU_MODEL}"
    volumes:
      - ./skills/code-analysis:/skills:ro
      - ./skills/llm_utils.py:/app/skills/llm_utils.py:ro
      - ./.claude/skills:/app/.claude/skills:ro
      - ./.env:/app/.env:ro
    depends_on:
      proxy:
        condition: service_healthy
    restart: unless-stopped

  # ── Python Front-End Agent ──
  agent:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
    environment:
      SKILLSCALE_PROXY_XSUB: tcp://proxy:5444
      SKILLSCALE_PROXY_XPUB: tcp://proxy:5555
      SKILLSCALE_TIMEOUT: "30"
    depends_on:
      proxy:
        condition: service_healthy
      skill-server-data:
        condition: service_started
      skill-server-code:
        condition: service_started
    stdin_open: true
    tty: true
    restart: unless-stopped
